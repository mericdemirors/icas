{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, you can use the content from the GitHub repository licensed under the Apache License 2.0 to develop your own pip library, as long as you comply with the terms of the license. Here are the key points you need to follow to ensure compliance:\n",
    "\n",
    "1 - Provide a Copy of the License: You must include a copy of the Apache License 2.0 in your project. This can be done by including a LICENSE file in the root of your project directory.\n",
    "\n",
    "2 - State Changes: If you modify any files from the original project, you need to include a prominent notice stating that you have changed the files. This helps in distinguishing your work from the original.\n",
    "\n",
    "3 - Preserve Notices: You must retain all the copyright, patent, trademark, and attribution notices from the source form of the original work in your derived work. This includes any notices contained in a NOTICE file if one exists.\n",
    "\n",
    "4 - Include the NOTICE File: If the original project includes a NOTICE file, you need to include a readable copy of the attribution notices contained within it in at least one of the following places: within a NOTICE text file distributed as part of your project, within the source code or documentation, or within a display generated by your project, if applicable.\n",
    "\n",
    "5 - Add Your Own Notices: You can add your own copyright statements and additional notices, as long as they do not contradict the terms of the Apache License 2.0.\n",
    "\n",
    "6 - State Compliance: You must state that your use of the original project's files is in compliance with the Apache License 2.0. This can typically be done in your project's documentation or README file.\n",
    "\n",
    "Here's a brief example of how you can include the Apache License 2.0 in your project:\n",
    "\n",
    "1 - LICENSE File: Create a LICENSE file in the root of your project directory with the full text of the Apache License 2.0.\n",
    "\n",
    "2 - Notice of Changes: If you modify any files, add a comment at the top of each modified file:  \n",
    "\\# Modified by [Your Name] on [Date]  \n",
    "\\# Original file available at [URL to original file]\n",
    "\n",
    "3 - Retain Notices: Ensure that all original notices are preserved in your project.\n",
    "\n",
    "4 - README or Documentation: Include a statement in your README file that your project includes files licensed under the Apache License 2.0 and provide a link to the license.\n",
    "\n",
    "By following these steps, you ensure that you are respecting the terms of the Apache License 2.0 while developing your pip library using the content from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.morphology import flood_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import SamPredictor, sam_model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"/home/mericdemirors/Downloads/sam_vit_b_01ec64.pth\")\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/home/mericdemirors/Pictures/araba/araba.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point_coords points can be selected interactively\n",
    "# point_labels (np.ndarray or None): point labels can be color\n",
    "# box (np.ndarray or None): rectangle çekilerek yapılabilir\n",
    "\n",
    "# masks, _, _ = predictor.predict(<input_prompts>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[\"vit_b\"](checkpoint=\"/home/mericdemirors/Downloads/sam_vit_b_01ec64.pth\")\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/home/mericdemirors/Pictures/araba/araba.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = mask_generator.generate(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_preds = [x[\"segmentation\"] for x in masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_image = np.zeros(image.shape[:2], dtype=np.int16)\n",
    "for e,segment_mask in enumerate(mask_preds):\n",
    "    labeled_image[segment_mask] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_pixels = np.where(labeled_image == 0)\n",
    "segment_id = labeled_image.max()+1\n",
    "while len(segment_pixels[0]) != 0: # while image has pixels with value 0 which means non-labeled segment\n",
    "    ri, ci = segment_pixels[0][0], segment_pixels[1][0] # get a segment pixel\n",
    "    \n",
    "    labeled_image = flood_fill(labeled_image, (ri, ci), segment_id, connectivity=1, in_place=True) # floodfill segment\n",
    "    extracted_segment = np.array(labeled_image == labeled_image[ri][ci]).astype(np.int16) # extract only segment as binary\n",
    "    extracted_segment = cv2.dilate(extracted_segment, np.ones((3,3)), iterations=1) # expand segment borders by one pixel to remove edges\n",
    "    np.putmask(labeled_image, extracted_segment != 0, segment_id) # overwrite expanded segment to labeled_image\n",
    "\n",
    "    segment_id = segment_id + 1\n",
    "    segment_pixels = np.where(labeled_image == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"i\", labeled_image.astype(np.uint8))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "490-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

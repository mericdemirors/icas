{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates test image\n",
    "def generate_image(character_to_put_on, size=300, x=60, y=240, rand_RGB_value=0, rand_xy_value = 5):\n",
    "    \"\"\"function to generate test dataset images\n",
    "\n",
    "    Args:\n",
    "        character_to_put_on (str): character to write on image\n",
    "        size (int, optional): size of image. Defaults to 300.\n",
    "        x (int, optional): x coordinate of character. Defaults to 60.\n",
    "        y (int, optional): y coordinate of character. Defaults to 240.\n",
    "        rand_RGB_value (int, optional): random RGB shift. Defaults to 0.\n",
    "        rand_xy_value (int, optional): random coordinate shift. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: prepared image\n",
    "    \"\"\"\n",
    "    bg = (220 + random.randint(-rand_RGB_value, rand_RGB_value),\n",
    "          245 + random.randint(-rand_RGB_value, rand_RGB_value),\n",
    "          245 + random.randint(-rand_RGB_value, rand_RGB_value))\n",
    "    background = np.full((size, size, 3), bg, dtype=np.uint8)\n",
    "    \n",
    "    # put given character text over background\n",
    "    background = cv2.putText(background, character_to_put_on,\n",
    "                             (x + random.randint(-rand_xy_value, rand_xy_value),\n",
    "                              y + random.randint(-rand_xy_value, rand_xy_value)), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 9, (0,0,0), 45, cv2.LINE_AA) \n",
    "\n",
    "    return background\n",
    "\n",
    "# generates test dataset\n",
    "def generate_test_dataset(path, count):\n",
    "    \"\"\"function to generate test dataset\n",
    "\n",
    "    Args:\n",
    "        path (str): folder path to generate images in\n",
    "        count (int): number of images\n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    for i in range(count):\n",
    "        character = random.choice(\"0123456789\")\n",
    "        image = generate_image(character)\n",
    "        cv2.imwrite(os.path.join(path, str(i) + character + \".png\"), image)\n",
    "\n",
    "test_path = \"here\"\n",
    "try:\n",
    "    shutil.rmtree(test_path)\n",
    "except:\n",
    "    pass\n",
    "generate_test_dataset(test_path, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.x = os.listdir(self.root_dir)\n",
    "        self.num_samples = len(self.x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.x[idx]\n",
    "        image_path = os.path.join(self.root_dir, image_name)\n",
    "        \n",
    "        image = cv2.imread(image_path).astype(np.float32)/255\n",
    "        image = np.moveaxis(image, 2, 0)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerOf2sAtLeast256(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PowerOf2sAtLeast256, self).__init__()\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=(1,1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=(1,1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=(1,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True))\n",
    "        \n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=(1,1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True))\n",
    "            \n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True))\n",
    "            \n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.4),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True))\n",
    "            \n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.ReLU(inplace=True))\n",
    "        # ------------------------------------------------------------------------------------------------------------ #\n",
    "        self.decoder6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1, output_padding=0),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.unpool7 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.decoder7 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, output_padding=0),\n",
    "            #nn.BatchNorm2d(),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.unpool8 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.decoder8 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, output_padding=0),\n",
    "            #nn.BatchNorm2d(),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.unpool9 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.decoder9 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.4))\n",
    "        \n",
    "        self.unpool10 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.decoder10 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, indices1 = self.encoder1(x)\n",
    "        # print(\"encoder1:\", x.shape, indices1.shape)\n",
    "        x, indices2 = self.encoder2(x)\n",
    "        # print(\"encoder2:\", x.shape, indices2.shape)\n",
    "        x, indices3 = self.encoder3(x)\n",
    "        # print(\"encoder3:\", x.shape, indices3.shape)\n",
    "        x, indices4 = self.encoder4(x)\n",
    "        # print(\"encoder4:\", x.shape, indices4.shape)\n",
    "        x = self.encoder5(x)\n",
    "        # print(\"encoder5: \", x.shape)\n",
    "        # print(\"---------------------------------------\")\n",
    "        x = self.decoder6(x)\n",
    "        # print(\"decoder6: \", x.shape)\n",
    "        x = self.unpool7(x, indices4)\n",
    "        # print(\"unpool6: \", x.shape)\n",
    "        x = self.decoder7(x)\n",
    "        # print(\"decoder7: \", x.shape)\n",
    "        x = self.unpool8(x, indices3)\n",
    "        # print(\"unpool7: \", x.shape)\n",
    "        x = self.decoder8(x)\n",
    "        # print(\"decoder8: \", x.shape)\n",
    "        x = self.unpool9(x, indices2)\n",
    "        # print(\"unpool8: \", x.shape)\n",
    "        x = self.decoder9(x)\n",
    "        # print(\"decoder9: \", x.shape)\n",
    "        x = self.unpool10(x, indices1)\n",
    "        # print(\"unpool9: \", x.shape)\n",
    "        x = self.decoder10(x)\n",
    "        # print(\"decoder10: \", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerOf2sAtMost128(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PowerOf2sAtMost128, self).__init__()\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=(1,1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=(1,1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=(1,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True))\n",
    "        \n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True))\n",
    "            \n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.ReLU(inplace=True))\n",
    "        # ------------------------------------------------------------------------------------------------------------ #\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1, output_padding=0),\n",
    "            nn.ReLU(inplace=True))\n",
    "                \n",
    "        self.unpool5 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1, output_padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.4))\n",
    "        \n",
    "        self.unpool6 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.decoder6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, indices1 = self.encoder1(x)\n",
    "        # print(\"encoder1:\", x.shape, indices1.shape)\n",
    "        x, indices2 = self.encoder2(x)\n",
    "        # print(\"encoder2:\", x.shape, indices2.shape)\n",
    "        x = self.encoder3(x)\n",
    "        # print(\"encoder3:\", x.shape)\n",
    "        # print(\"---------------------------------------\")\n",
    "        x = self.decoder4(x)\n",
    "        # print(\"decoder4: \", x.shape)\n",
    "        x = self.unpool5(x, indices2)\n",
    "        # print(\"unpool5: \", x.shape)\n",
    "        x = self.decoder5(x)\n",
    "        # print(\"decoder5: \", x.shape)\n",
    "        x = self.unpool6(x, indices1)\n",
    "        # print(\"unpool6: \", x.shape)\n",
    "        x = self.decoder6(x)\n",
    "        # print(\"decoder6: \", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameter count of PowerOf2sAtMost128: 785155\n",
      "Total parameter count of PowerOf2sAtLeast256: 1375491\n"
     ]
    }
   ],
   "source": [
    "print(\"Total parameter count of PowerOf2sAtMost128:\", sum(p.numel() for p in PowerOf2sAtMost128().parameters() if p.requires_grad))\n",
    "print(\"Total parameter count of PowerOf2sAtLeast256:\", sum(p.numel() for p in PowerOf2sAtLeast256().parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerOf2sAtMost128 input: torch.Size([4, 3, 128, 128]) output: torch.Size([4, 3, 128, 128]) True\n",
      "PowerOf2sAtLeast256 input: torch.Size([4, 3, 256, 256]) output: torch.Size([4, 3, 256, 256]) True\n"
     ]
    }
   ],
   "source": [
    "model_input = torch.randn(4, 3, 128, 128)\n",
    "model = PowerOf2sAtMost128()\n",
    "with torch.no_grad():\n",
    "    model_output = model(model_input)\n",
    "\n",
    "print(\"PowerOf2sAtMost128 input:\", model_input.shape, \"output:\", model_output.shape, model_input.shape == model_output.shape)\n",
    "\n",
    "model_input = torch.randn(4, 3, 256, 256)\n",
    "model = PowerOf2sAtLeast256()\n",
    "with torch.no_grad():\n",
    "    model_output = model(model_input)\n",
    "\n",
    "print(\"PowerOf2sAtLeast256 input:\", model_input.shape, \"output:\", model_output.shape, model_input.shape == model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "490-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

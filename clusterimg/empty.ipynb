{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, HDBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DL_Datasets import *\n",
    "from DL_Models import *\n",
    "from DL_ModelTrainer import ModelTrainer\n",
    "\n",
    "dataset = ImageDataset(\"heredenene\")\n",
    "model = PowerOf2s256andAbove()\n",
    "mt = ModelTrainer(num_of_epochs=100, lr=0.001,\n",
    "                  batch_size=16, loss_type=\"mse\",\n",
    "                  dataset=dataset, model=model,\n",
    "                  ckpt_path=\"heredenene_PowerOf2s256andAbove_mse_05:16:19:01:53/min_loss:0.06544473022222519_epoch:19.pth\")\n",
    "\n",
    "features = mt()\n",
    "paths = list(features.keys())\n",
    "reps = np.array(list(features.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(method=\"\", number_of_clusters=[None], max_iter=[200], DBSCAN_eps=[0.5], DBSCAN_min_samples=[5], HDBSCAN_min_cluster_size=[5], HDBSCAN_max_cluster_size=[None], verbose=0):\n",
    "    def calculate_grid_search():\n",
    "        param_grid = []\n",
    "        if method == \"kmeans\":\n",
    "            param_grid = list(itertools.product(number_of_clusters, max_iter))\n",
    "        elif method == \"hierarchy\":\n",
    "            param_grid = number_of_clusters\n",
    "        elif method == \"DBSCAN\":\n",
    "            param_grid = list(itertools.product(DBSCAN_eps, DBSCAN_min_samples))\n",
    "        elif method == \"gaussian\":\n",
    "            param_grid = list(itertools.product(number_of_clusters, max_iter))\n",
    "        elif method == \"HDBSCAN\":\n",
    "            param_grid = list(itertools.product(HDBSCAN_min_cluster_size, HDBSCAN_max_cluster_size))\n",
    "        \n",
    "        return param_grid\n",
    "    param_grid = calculate_grid_search()\n",
    "\n",
    "    models = []\n",
    "    for params in param_grid:\n",
    "        if method == \"kmeans\":\n",
    "            n_clusters, max_iter = params\n",
    "            models.append(KMeans(n_clusters=n_clusters, max_iter=max_iter, verbose=verbose))\n",
    "        elif method == \"hierarchy\":\n",
    "            n_clusters = params\n",
    "            models.append(AgglomerativeClustering(n_clusters=n_clusters))\n",
    "        elif method == \"DBSCAN\":\n",
    "            eps, min_samples = params\n",
    "            models.append(DBSCAN(eps=eps, min_samples=min_samples))\n",
    "        elif method == \"gaussian\":\n",
    "            n_clusters, max_iter = params\n",
    "            models.append(GaussianMixture(n_components=n_clusters, max_iter=max_iter, verbose=verbose))\n",
    "        elif method == \"HDBSCAN\":\n",
    "            min_cluster_size, max_cluster_size = params\n",
    "            models.append(HDBSCAN(min_cluster_size=min_cluster_size, max_cluster_size=max_cluster_size))\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(models, data):\n",
    "    silhouette_scores, db_scores, ch_scores = [], [], []\n",
    "    for model in tqdm(models):\n",
    "        labels = model.fit_predict(data)\n",
    "        \n",
    "        silhouette_scores.append(silhouette_score(data, labels))\n",
    "        db_scores.append(davies_bouldin_score(data, labels))\n",
    "        ch_scores.append(calinski_harabasz_score(data, labels))\n",
    "\n",
    "    silhouette_scores, db_scores, ch_scores = np.array(silhouette_scores), np.array(db_scores), np.array(ch_scores)\n",
    "    silhouette_scores = (silhouette_scores - silhouette_scores.min())/(silhouette_scores.max()-silhouette_scores.min())\n",
    "    db_scores = (db_scores - db_scores.min())/(db_scores.max()-db_scores.min())\n",
    "    ch_scores = (ch_scores - ch_scores.min())/(ch_scores.max()-ch_scores.min())\n",
    "    \n",
    "    combined_scores = silhouette_scores - db_scores + ch_scores\n",
    "    best_model = models[np.argmax(combined_scores)]\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    models = get_models(\"hierarchy\", number_of_clusters=[3,4,5,6,7,8,9], max_iter=[50,75,100], verbose=0)\n",
    "    best_model = find_best_model(models, reps)\n",
    "    labels = best_model.fit_predict(reps)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "490-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

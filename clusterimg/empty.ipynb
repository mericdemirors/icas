{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, HDBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DL_Datasets import *\n",
    "from DL_Models import *\n",
    "from DL_ModelTrainer import ModelTrainer\n",
    "\n",
    "dataset = ImageDataset(\"heredenene\")\n",
    "model = PowerOf2s256andAbove()\n",
    "mt = ModelTrainer(num_of_epochs=1, lr=0.001,\n",
    "                  batch_size=16, loss_type=\"mse\",\n",
    "                  dataset=dataset, model=model,\n",
    "                  ckpt_path=\"heredenene_PowerOf2s256andAbove_mse_05:16:19:01:53/min_loss:0.06544473022222519_epoch:19.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.get_features(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DL_Clustering():\n",
    "    def __init__(self, model_trainer, method, number_of_clusters=[None], max_iter=[200], DBSCAN_eps=[0.5],\n",
    "                DBSCAN_min_samples=[5], HDBSCAN_min_cluster_size=[5], HDBSCAN_max_cluster_size=[None]):\n",
    "        self.model_trainer = model_trainer\n",
    "        self.method = method\n",
    "        self.number_of_clusters = number_of_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.DBSCAN_eps = DBSCAN_eps\n",
    "        self.DBSCAN_min_samples = DBSCAN_min_samples\n",
    "        self.HDBSCAN_min_cluster_size = HDBSCAN_min_cluster_size\n",
    "        self.HDBSCAN_max_cluster_size = HDBSCAN_max_cluster_size        \n",
    "\n",
    "        pass\n",
    "    \n",
    "    def __str__(self, verbose=0):\n",
    "        \"\"\"casting to string method for printing/debugging object attributes\n",
    "\n",
    "        Returns:\n",
    "            str: object attribute information\n",
    "        \"\"\"\n",
    "        attributes = vars(self)\n",
    "        attr_strings = [f\"{key}: {value}\" for key, value in attributes.items()]\n",
    "        return \"-\"*70 + \"\\n\" + \"\\n\".join(attr_strings) + \"\\n\" + \"-\"*70\n",
    "\n",
    "    def arguman_check(self, verbose=0):\n",
    "        valid_methods = [\"kmeans\", \"hierarchy\", \"DBSCAN\", \"gaussian\", \"HDBSCAN\"]\n",
    "        if self.method not in valid_methods:\n",
    "            6/0\n",
    "\n",
    "        \n",
    "    def get_models(self, verbose=0):\n",
    "        def calculate_grid_search():\n",
    "            param_grid = []\n",
    "            if self.method == \"kmeans\":\n",
    "                param_grid = list(itertools.product(number_of_clusters, max_iter))\n",
    "            elif self.method == \"hierarchy\":\n",
    "                param_grid = number_of_clusters\n",
    "            elif self.method == \"DBSCAN\":\n",
    "                param_grid = list(itertools.product(DBSCAN_eps, DBSCAN_min_samples))\n",
    "            elif self.method == \"gaussian\":\n",
    "                param_grid = list(itertools.product(number_of_clusters, max_iter))\n",
    "            elif self.method == \"HDBSCAN\":\n",
    "                param_grid = list(itertools.product(HDBSCAN_min_cluster_size, HDBSCAN_max_cluster_size))\n",
    "            \n",
    "            return param_grid\n",
    "        param_grid = calculate_grid_search()\n",
    "\n",
    "        models = []\n",
    "        for params in param_grid:\n",
    "            if self.method == \"kmeans\":\n",
    "                n_clusters, max_iter = params\n",
    "                models.append(KMeans(n_clusters=n_clusters, max_iter=max_iter, verbose=verbose))\n",
    "            elif self.method == \"hierarchy\":\n",
    "                n_clusters = params\n",
    "                models.append(AgglomerativeClustering(n_clusters=n_clusters))\n",
    "            elif self.method == \"DBSCAN\":\n",
    "                eps, min_samples = params\n",
    "                models.append(DBSCAN(eps=eps, min_samples=min_samples))\n",
    "            elif self.method == \"gaussian\":\n",
    "                n_clusters, max_iter = params\n",
    "                models.append(GaussianMixture(n_components=n_clusters, max_iter=max_iter, verbose=verbose))\n",
    "            elif self.method == \"HDBSCAN\":\n",
    "                min_cluster_size, max_cluster_size = params\n",
    "                models.append(HDBSCAN(min_cluster_size=min_cluster_size, max_cluster_size=max_cluster_size))\n",
    "\n",
    "        return models\n",
    "\n",
    "    def find_best_model(self, verbose=0):\n",
    "        silhouette_scores, db_scores, ch_scores = [], [], []\n",
    "        for model in tqdm(self.models):\n",
    "            labels = model.fit_predict(self.reps)\n",
    "            \n",
    "            silhouette_scores.append(silhouette_score(self.reps, labels))\n",
    "            db_scores.append(davies_bouldin_score(self.reps, labels))\n",
    "            ch_scores.append(calinski_harabasz_score(self.reps, labels))\n",
    "\n",
    "        silhouette_scores, db_scores, ch_scores = np.array(silhouette_scores), np.array(db_scores), np.array(ch_scores)\n",
    "        silhouette_scores = (silhouette_scores - silhouette_scores.min())/(silhouette_scores.max()-silhouette_scores.min())\n",
    "        db_scores = (db_scores - db_scores.min())/(db_scores.max()-db_scores.min())\n",
    "        ch_scores = (ch_scores - ch_scores.min())/(ch_scores.max()-ch_scores.min())\n",
    "        \n",
    "        combined_scores = silhouette_scores - db_scores + ch_scores\n",
    "        best_model = self.models[np.argmax(combined_scores)]\n",
    "        \n",
    "        return best_model\n",
    "\n",
    "    def clusters_from_labels(self, verbose=0):\n",
    "        clusters = {}\n",
    "        for file, cluster_id in zip(self.paths, self.labels):\n",
    "            if cluster_id not in clusters:\n",
    "                clusters[cluster_id] = []\n",
    "            clusters[cluster_id].append(file)\n",
    "        return clusters\n",
    "\n",
    "    def calculate_batch_similarity(self, verbose=0):\n",
    "        features = self.model_trainer()\n",
    "        self.paths = list(features.keys())\n",
    "        self.reps = np.array(list(features.values()))\n",
    "\n",
    "        self.models = self.get_models()\n",
    "        self.best_model = self.find_best_model()\n",
    "        self.labels = self.best_model.fit_predict(self.reps)        \n",
    "\n",
    "\n",
    "    def calculate_template_similarity(self, verbose=0):\n",
    "        pass\n",
    "\n",
    "    def merge_clusters_my_templates(self, verbose=0):\n",
    "        pass\n",
    "\n",
    "    def create_clusters(self, verbose=0):\n",
    "        clusters = self.clusters_from_labels()\n",
    "        write_clusters(clusters, batch_idx, self.result_container_folder, outliers, self.transfer, verbose=verbose-1)\n",
    "        if verbose > 0:\n",
    "            print(\"-\"*70)\n",
    "\n",
    "    def process(self, verbose=0):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, verbose=0):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "490-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

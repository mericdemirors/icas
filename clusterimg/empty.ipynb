{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, HDBSCAN\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_dataset(path, count, size=256, x=40, y=220, rand_RGB_value=0, rand_xy_value=5, font_scale=9, font_thickness=45):\n",
    "    \"\"\"function to generate test dataset\n",
    "\n",
    "    Args:\n",
    "        path (str): folder path to generate images in\n",
    "        count (int): number of images\n",
    "        size (int, optional): size of image. Defaults to 256.\n",
    "        x (int, optional): x coordinate of character. Defaults to 40.\n",
    "        y (int, optional): y coordinate of character. Defaults to 220.\n",
    "        rand_RGB_value (int, optional): random RGB shift. Defaults to 0.\n",
    "        rand_xy_value (int, optional): random coordinate shift. Defaults to 5.\n",
    "        font_scale (int, optional): font scale. Defaults to 9.\n",
    "        font_thickness (int, optional): font thickness. Defaults to 45.\n",
    "\n",
    "    \"\"\"\n",
    "    # generates test image\n",
    "    def generate_image(character_to_put_on):\n",
    "        \"\"\"function to generate test dataset images\n",
    "\n",
    "        Args:\n",
    "            character_to_put_on (str): character to write on image\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: prepared image\n",
    "        \"\"\"\n",
    "        bg = (220 + random.randint(-rand_RGB_value, rand_RGB_value),\n",
    "            245 + random.randint(-rand_RGB_value, rand_RGB_value),\n",
    "            245 + random.randint(-rand_RGB_value, rand_RGB_value))\n",
    "        background = np.full((size, size, 3), bg, dtype=np.uint8)\n",
    "        \n",
    "        # put given character text over background\n",
    "        background = cv2.putText(background, character_to_put_on,\n",
    "                                (x + random.randint(-rand_xy_value, rand_xy_value),\n",
    "                                y + random.randint(-rand_xy_value, rand_xy_value)), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0,0,0), font_thickness, cv2.LINE_AA) \n",
    "\n",
    "        return background\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    for i in range(count):\n",
    "        character = random.choice(\"0123456789\")\n",
    "        image = generate_image(character)\n",
    "        cv2.imwrite(os.path.join(path, str(i) + character + \".png\"), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_test_dataset(\"heredenene\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DL_Datasets import *\n",
    "from DL_Models import *\n",
    "from DL_ModelTrainer import ModelTrainer\n",
    "\n",
    "dataset = ImageDataset(\"heredenene\")\n",
    "model = PowerOf2s256andAbove()\n",
    "mt = ModelTrainer(num_of_epochs=100, lr=0.001,\n",
    "                  batch_size=16, loss_type=\"mse\",\n",
    "                  dataset=dataset, model=model,\n",
    "                  ckpt_path=\"heredenene_PowerOf2s256andAbove_mse_05:16:19:01:53/min_loss:0.06544473022222519_epoch:19.pth\")\n",
    "\n",
    "features = mt()\n",
    "paths = list(features.keys())\n",
    "reps = np.array(list(features.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOMATIC NUMBER OF CLUSTER FINDING WILL BE DONE WITH ELBOW METHOD\n",
    "# AUTOMATIC NUMBER OF CLUSTER FINDING WILL BE DONE WITH ELBOW METHOD\n",
    "# AUTOMATIC NUMBER OF CLUSTER FINDING WILL BE DONE WITH ELBOW METHOD\n",
    "# AUTOMATIC NUMBER OF CLUSTER FINDING WILL BE DONE WITH ELBOW METHOD\n",
    "def get_labels(method=\"\", number_of_clusters=None, max_iter=200, DBSCAN_eps=0.5, DBSCAN_min_samples=5, HDBSCAN_min_cluster_size=5, HDBSCAN_max_cluster_size=None, verbose=0):\n",
    "    if method == \"\":\n",
    "        kmeans = KMeans(n_clusters=number_of_clusters, max_iter=max_iter, verbose=verbose)\n",
    "        labels = kmeans.fit_predict(reps)\n",
    "    elif method == \"\":\n",
    "        agg_clustering = AgglomerativeClustering(n_clusters=number_of_clusters)\n",
    "        labels = agg_clustering.fit_predict(reps)\n",
    "    elif method == \"\":\n",
    "        dbscan = DBSCAN(eps=DBSCAN_eps, min_samples=DBSCAN_min_samples)\n",
    "        labels = dbscan.fit_predict(reps)\n",
    "    elif method == \"\":\n",
    "        gmm = GaussianMixture(n_components=number_of_clusters, max_iter=max_iter, verbose=verbose)\n",
    "        labels = gmm.fit_predict(reps)\n",
    "    elif method == \"\":\n",
    "        hdb = HDBSCAN(min_cluster_size=HDBSCAN_min_cluster_size, max_cluster_size=HDBSCAN_max_cluster_size)\n",
    "        labels = hdb.fit_predict(reps)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "490-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
